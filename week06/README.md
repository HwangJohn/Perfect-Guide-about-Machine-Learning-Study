## 오늘의 목표
- 4장 [ XGBoost 논문 공부 ]
	- 1) 저번 주에 공식 문서 봤나요?
		- [XGBoost Document](https://xgboost.readthedocs.io/en/latest/index.html)
	- 2) 논문 읽기
	

### XGBoost 참고 자료
- [XGBoost Paper](https://arxiv.org/abs/1603.02754)
- [XGBoost 사용하기](https://brunch.co.kr/@snobberys/137)
- [XGBoost Document](https://xgboost.readthedocs.io/en/latest/index.html)
- [Introduction to Boosted Tress PPT](https://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf?fbclid=IwAR0gGntURg4U24l6Fit-DLpVNBb_BtgMjzlSg3NYdb8jI44JLHLH-0Zluis)
- [boosting 기법 이해 (bagging vs boosting)](https://www.slideshare.net/freepsw/boosting-bagging-vs-boosting)

### Gradient 
- [Gradient Boosting Algorithm의 직관적 이해](https://3months.tistory.com/368)
- [Gradient boosting performs gradient descent](https://explained.ai/gradient-boosting/descent.html)
- [Gradient Boosting(컨벡스 최적화)](https://wikidocs.net/19037)

### Kaggle 커널
- [Using XGBoost with Scikit-learn](https://www.kaggle.com/stuarthallows/using-xgboost-with-scikit-learn)

### Catboost
- [Catboost의 아이디어](https://ishuca.tistory.com/418)
- [Catboost 설명](https://gentlej90.tistory.com/100)
